# config/llm/claude-3.7-sonnet.yaml - Sub Agent LLM Configuration (Claude 3.7 Sonnet)
provider: "claude_openrouter"
model_name: "anthropic/claude-sonnet-4"

# Basic LLM parameters
async_client: true
temperature: 0.3
top_p: 0.95
min_p: 0.0
top_k: -1
max_tokens: 32000
# max_context_length: 190000  # deprecated, no longer used

# Provider specific settings
openrouter_base_url: https://openrouter.ai/api/v1
openrouter_provider: "anthropic"  # Force provider
disable_cache_control: false

# Base URLs
openai_base_url: null
anthropic_base_url: https://api.anthropic.com

# Other settings
keep_tool_result: -1
oai_tool_thinking: false 